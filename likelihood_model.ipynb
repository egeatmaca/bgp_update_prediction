{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1fd9f6c-6358-41f9-88e6-2fd357ac4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6e136-10a0-48c0-8ee2-057b9e50dc32",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a42a94-d50d-4c44-865c-776e077bdf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "AS_UPDATES_ROOT_DIR = './data/asn_updates'\n",
    "\n",
    "as_updates = {}\n",
    "as_updates_dirs = sorted(glob(AS_UPDATES_ROOT_DIR+'/*'))\n",
    "for dir_path in tqdm(as_updates_dirs):\n",
    "    asn = dir_path.split('/')[-1]\n",
    "    as_updates_files = sorted(glob(dir_path+'/*'))\n",
    "    as_df_list = [pd.read_csv(file_path) for file_path in as_updates_files]\n",
    "    as_df =  pd.concat(as_df_list).reset_index(drop=True)\n",
    "    del as_df_list\n",
    "    gc.collect()\n",
    "    as_df = as_df.sort_values('time')\n",
    "    as_updates[asn] = as_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d08ed-4ada-4183-9990-b24aa370fba2",
   "metadata": {},
   "source": [
    "# Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3098ed7e-3529-43ae-ba67-e278f0ca68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "    df['minute'] = df.time // 60\n",
    "    df = df.groupby('minute')[['prefix']]\\\n",
    "                       .count()\\\n",
    "                       .rename(columns={'prefix': 'updates'})\n",
    "    minutes = pd.Series(df.index, index=df.index)\n",
    "    df['periods_before_update'] = minutes - minutes.shift(1)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca86c47-31be-4e94-a651-444f66946cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_index(df):\n",
    "    index_interpolated = np.arange(int(df.index.min()), int(df.index.max()))\n",
    "    df = df.reindex(index_interpolated).fillna({'updates': 0})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b366c28-d27b-4cce-a9e3-489207c60955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(df, feature_cols, target_col, lag):    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(df.shape[0]-lag):\n",
    "        X.append(df.iloc[i:i+lag][feature_cols].to_numpy().reshape(-1))\n",
    "        y.append(df.iloc[i+lag][target_col])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14decbb0-60c2-48a8-a831-f0d5e4230ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_croston_zero_rows(X, y):\n",
    "    zero_rows = {}\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        row_ = X[i].copy()\n",
    "        n_zero_rows = int(row_[-1] - 1)\n",
    "\n",
    "        if n_zero_rows > 0:\n",
    "            row_[-2] = 0\n",
    "            row_[-1] = 1\n",
    "            zero_rows[i] = [row_]\n",
    "        \n",
    "        for _ in range(n_zero_rows-1):\n",
    "            row_ = row_.copy()\n",
    "            row_[-1] += 1\n",
    "            zero_rows[i].append(row_)\n",
    "    \n",
    "    for i in sorted(zero_rows.keys())[-1::-1]:\n",
    "        X_zeros = np.array(zero_rows[i])\n",
    "        y_zeros = np.zeros(X_zeros.shape[0])\n",
    "        \n",
    "        X_before = X[:i]\n",
    "        y_before = y[:i]\n",
    "        \n",
    "        X_after = X[i:]\n",
    "        y_after = y[i:]\n",
    "    \n",
    "        X = np.concatenate([X_before, X_zeros, X_after])\n",
    "        y = np.concatenate([y_before, y_zeros, y_after])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34525908-84bf-4336-b9e8-71526444e9be",
   "metadata": {},
   "source": [
    "# Single AS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c15fd5c0-1cd6-42fd-8d6a-22924bd7fb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 24 * 60\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788a3ce-0661-484a-a362-44cbd779d809",
   "metadata": {},
   "source": [
    "## AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "047c9721-7c0f-44c9-af45-1239f31a0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_features(as_updates['25139'])\n",
    "df_ar = interpolate_index(df)\n",
    "X, y = make_sequences(df_ar, ['updates'], 'updates', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f0932d-1c69-43bc-8d62-dd980d9f71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e527edc3-9ca1-464f-b0ba-a1ea16d161f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18609, 20), (18609,), (1440, 20), (1440,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d709d9a-a231-47ae-a7fd-d2824bc9a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec1cc4bf-0112-4f98-ace4-950812bf5a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = np.concat([np.ones((X_train.shape[0],1)), X_train], axis=1)\n",
    "X_test_reg = np.concat([np.ones((X_test.shape[0],1)), X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ad6ba45-c782-41e4-9bf7-1e46554cb70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9680555555555556\n",
      "Recall: 0.7704918032786885\n",
      "Precision: 0.9724137931034482\n",
      "F1: 0.8597560975609756\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_reg, y_train)\n",
    "y_pred = model.predict(X_test_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccfdfdbf-ccc8-4d47-9e62-46b245e63913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784722222222222\n",
      "Recall: 0.8961748633879781\n",
      "Precision: 0.9318181818181818\n",
      "F1: 0.9136490250696379\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16beac2c-a1cc-449d-b912-ee79cea64817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2687, number of negative: 15922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 18609, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144392 -> initscore=-1.779276\n",
      "[LightGBM] [Info] Start training from score -1.779276\n",
      "Accuracy: 0.98125\n",
      "Recall: 0.8852459016393442\n",
      "Precision: 0.9642857142857143\n",
      "F1: 0.9230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6314f42-f774-41d5-ac75-d05c2e3a40a6",
   "metadata": {},
   "source": [
    "## Croston-like AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f8bd6e4-e08b-4daf-88ac-2996d2c8a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_features(as_updates['25139'])\n",
    "X, y = make_sequences(df, ['updates', 'periods_before_update'], 'updates', 20)\n",
    "X, y = insert_croston_zero_rows(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "969b3c8c-a77b-4a5f-a9ce-c8a7e753ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b393e020-96c8-4de9-a9a9-ee9704c661de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18447, 40), (18447,), (1440, 40), (1440,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6492bb50-bcf6-4adf-8430-ef49fba559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96e56728-b95f-4542-9227-e163af9135b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = np.concat([np.ones((X_train.shape[0],1)), X_train], axis=1)\n",
    "X_test_reg = np.concat([np.ones((X_test.shape[0],1)), X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "501433ee-c6a6-4771-9b65-2e9c55d6d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9916666666666667\n",
      "Recall: 0.9347826086956522\n",
      "Precision: 1.0\n",
      "F1: 0.9662921348314607\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_reg, y_train)\n",
    "y_pred = model.predict(X_test_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2e6fe5a-bd55-4c37-80ef-eaf667c442f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "531ed736-8533-461c-ae13-c38dea9b15ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2670, number of negative: 15777\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 18447, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144739 -> initscore=-1.776475\n",
      "[LightGBM] [Info] Start training from score -1.776475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42125f4d-238c-4a65-a0dc-06a17c24ebc6",
   "metadata": {},
   "source": [
    "# Multiple AS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853ded9-7dd5-4ee8-b136-0172f2f42e33",
   "metadata": {},
   "source": [
    "## AR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314c227-13e6-4eb7-9b1c-ddeee940fd6b",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89fd5328-6923-4620-a67f-5263e53730d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Processing AS: 11913\n",
      "1 | Processing AS: 131292\n",
      "2 | Processing AS: 133840\n",
      "3 | Processing AS: 134645\n",
      "4 | Processing AS: 135101\n",
      "5 | Processing AS: 136844\n",
      "6 | Processing AS: 136991\n",
      "7 | Processing AS: 138146\n",
      "8 | Processing AS: 138630\n",
      "9 | Processing AS: 138645\n",
      "10 | Processing AS: 139002\n",
      "11 | Processing AS: 139054\n",
      "12 | Processing AS: 139245\n",
      "13 | Processing AS: 141139\n",
      "14 | Processing AS: 142354\n",
      "15 | Processing AS: 147182\n",
      "16 | Processing AS: 149001\n",
      "17 | Processing AS: 149282\n",
      "18 | Processing AS: 151853\n",
      "19 | Processing AS: 152438\n",
      "20 | Processing AS: 18036\n",
      "21 | Processing AS: 18109\n",
      "22 | Processing AS: 19263\n",
      "23 | Processing AS: 197915\n",
      "24 | Processing AS: 198239\n",
      "25 | Processing AS: 200179\n",
      "26 | Processing AS: 200400\n",
      "27 | Processing AS: 200536\n",
      "28 | Processing AS: 200914\n",
      "29 | Processing AS: 201547\n",
      "30 | Processing AS: 2018\n",
      "31 | Processing AS: 202140\n",
      "32 | Processing AS: 202188\n",
      "33 | Processing AS: 202627\n",
      "34 | Processing AS: 204446\n",
      "35 | Processing AS: 20783\n",
      "36 | Processing AS: 208115\n",
      "37 | Processing AS: 208985\n",
      "38 | Processing AS: 20986\n",
      "39 | Processing AS: 210630\n",
      "40 | Processing AS: 212863\n",
      "41 | Processing AS: 212873\n",
      "42 | Processing AS: 212883\n",
      "43 | Processing AS: 215694\n",
      "44 | Processing AS: 23553\n",
      "45 | Processing AS: 24455\n",
      "46 | Processing AS: 24700\n",
      "47 | Processing AS: 24852\n",
      "48 | Processing AS: 25139\n",
      "49 | Processing AS: 25308\n",
      "50 | Processing AS: 25581\n",
      "51 | Processing AS: 263277\n",
      "52 | Processing AS: 263608\n",
      "53 | Processing AS: 263927\n",
      "54 | Processing AS: 266107\n",
      "55 | Processing AS: 266440\n",
      "56 | Processing AS: 266443\n",
      "57 | Processing AS: 267340\n",
      "58 | Processing AS: 268063\n",
      "59 | Processing AS: 26852\n",
      "60 | Processing AS: 268846\n",
      "61 | Processing AS: 269172\n",
      "62 | Processing AS: 270074\n",
      "63 | Processing AS: 270263\n",
      "64 | Processing AS: 27046\n",
      "65 | Processing AS: 271629\n",
      "66 | Processing AS: 29217\n",
      "67 | Processing AS: 30738\n",
      "68 | Processing AS: 31163\n",
      "69 | Processing AS: 328278\n",
      "70 | Processing AS: 328815\n",
      "71 | Processing AS: 328894\n",
      "72 | Processing AS: 33631\n",
      "73 | Processing AS: 34758\n",
      "74 | Processing AS: 36236\n",
      "75 | Processing AS: 39057\n",
      "76 | Processing AS: 393968\n",
      "77 | Processing AS: 394359\n",
      "78 | Processing AS: 39558\n",
      "79 | Processing AS: 395831\n",
      "80 | Processing AS: 399888\n",
      "81 | Processing AS: 400132\n",
      "82 | Processing AS: 41676\n",
      "83 | Processing AS: 42394\n",
      "84 | Processing AS: 42511\n",
      "85 | Processing AS: 43319\n",
      "86 | Processing AS: 44194\n",
      "87 | Processing AS: 44500\n",
      "88 | Processing AS: 46027\n",
      "89 | Processing AS: 49311\n",
      "90 | Processing AS: 49510\n",
      "91 | Processing AS: 5098\n",
      "92 | Processing AS: 53146\n",
      "93 | Processing AS: 56801\n",
      "94 | Processing AS: 57976\n",
      "95 | Processing AS: 58312\n",
      "96 | Processing AS: 58381\n",
      "97 | Processing AS: 60582\n",
      "98 | Processing AS: 8388\n",
      "99 | Processing AS: 9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "X_zero_shots = []\n",
    "y_zero_shots = []\n",
    "\n",
    "for i, (asn, df) in enumerate(as_updates.items()):\n",
    "    print(i, '| Processing AS:', asn)\n",
    "    df = calculate_features(df)\n",
    "    df = interpolate_index(df)\n",
    "    X, y = make_sequences(df, ['updates'], 'updates', 20)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        X_zero_shots.append(X)\n",
    "        y_zero_shots.append((y > 0).astype(int))\n",
    "    \n",
    "    X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "    X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)\n",
    "    X_trains.append(X_train)\n",
    "    y_trains.append(y_train)\n",
    "    X_tests.append(X_test)\n",
    "    y_tests.append(y_test)\n",
    "\n",
    "X_train = np.concatenate(X_trains)\n",
    "y_train = np.concatenate(y_trains)\n",
    "X_test = np.concatenate(X_tests)\n",
    "y_test = np.concatenate(y_tests)\n",
    "X_zero_shot = np.concatenate(X_zero_shots)\n",
    "y_zero_shot = np.concatenate(y_zero_shots)\n",
    "\n",
    "del X_trains\n",
    "del y_trains\n",
    "del X_tests\n",
    "del y_tests\n",
    "del X_zero_shots\n",
    "del y_zero_shots\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d87613a-8402-45aa-beae-55cc1db83efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1814183, 20), (1814183,), (144000, 20), (144000,), (198765, 20), (198765,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_zero_shot.shape, y_zero_shot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb106047-0b13-477d-a54d-b7bd53d58c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, y_train_test = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf4da46b-0d0b-4742-b409-8f5d0c06f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_test = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a309039b-5188-48d5-87ea-dbd41a512fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "X_train_test = scaler2.fit_transform(X_train_test)\n",
    "X_zero_shot = scaler2.transform(X_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be5e0a4e-d49c-4dd2-a59a-5d34888d89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = np.concat([np.ones((X_train.shape[0],1)), X_train], axis=1)\n",
    "X_test_reg = np.concat([np.ones((X_test.shape[0],1)), X_test], axis=1)\n",
    "\n",
    "X_train_test_reg = np.concat([np.ones((X_train_test.shape[0],1)), X_train_test], axis=1)\n",
    "X_zero_shot_reg = np.concat([np.ones((X_zero_shot.shape[0],1)), X_zero_shot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6f789-cd39-47c6-a563-dc12af3a3e36",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27c7cbcc-6d85-496d-bc42-528ef8491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500347222222222\n",
      "Recall: 0.2384785005512679\n",
      "Precision: 0.8824969400244798\n",
      "F1: 0.3754882388681538\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_reg, y_train)\n",
    "y_pred = model.predict(X_test_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43c0506f-ead2-4bf4-b748-70524b1c77e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>-1.215784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_1</th>\n",
       "      <td>0.275087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_2</th>\n",
       "      <td>0.039667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_3</th>\n",
       "      <td>0.046616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_4</th>\n",
       "      <td>0.066289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_5</th>\n",
       "      <td>0.129304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_6</th>\n",
       "      <td>0.161521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_7</th>\n",
       "      <td>0.039958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_8</th>\n",
       "      <td>0.102751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_9</th>\n",
       "      <td>0.094201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_10</th>\n",
       "      <td>0.037251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_11</th>\n",
       "      <td>0.254218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_12</th>\n",
       "      <td>0.061052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_13</th>\n",
       "      <td>0.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_14</th>\n",
       "      <td>0.086950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_15</th>\n",
       "      <td>0.105297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_16</th>\n",
       "      <td>0.114613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_17</th>\n",
       "      <td>0.130165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_18</th>\n",
       "      <td>0.180389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_19</th>\n",
       "      <td>0.247852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_20</th>\n",
       "      <td>4.516344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "bias       -1.215784\n",
       "updates_1   0.275087\n",
       "updates_2   0.039667\n",
       "updates_3   0.046616\n",
       "updates_4   0.066289\n",
       "updates_5   0.129304\n",
       "updates_6   0.161521\n",
       "updates_7   0.039958\n",
       "updates_8   0.102751\n",
       "updates_9   0.094201\n",
       "updates_10  0.037251\n",
       "updates_11  0.254218\n",
       "updates_12  0.061052\n",
       "updates_13  0.103739\n",
       "updates_14  0.086950\n",
       "updates_15  0.105297\n",
       "updates_16  0.114613\n",
       "updates_17  0.130165\n",
       "updates_18  0.180389\n",
       "updates_19  0.247852\n",
       "updates_20  4.516344"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['bias']\n",
    "for i in range(1, 21):\n",
    "    feature_names.extend([f'updates_{i}'])\n",
    "    \n",
    "pd.DataFrame(model.coef_, columns=feature_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38bece44-c88f-4227-8e4b-cda742ff481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9368450179860639\n",
      "Recall: 0.134440199823685\n",
      "Precision: 0.7035755478662054\n",
      "F1: 0.2257447727132548\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_test_reg, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910b122-03d4-463a-81dd-bdd381662138",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c30badb5-3938-41d3-b73f-9642b95843a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9573402777777777\n",
      "Recall: 0.5315325248070563\n",
      "Precision: 0.7179448994787788\n",
      "F1: 0.6108330693696548\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f47366c2-b281-47e1-9d8b-45db385bb5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972253666389958\n",
      "Recall: 0.6259917719659124\n",
      "Precision: 0.9525992174399106\n",
      "F1: 0.7555082679434322\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd13c17-9046-4b56-8bda-28707f696620",
   "metadata": {},
   "source": [
    "### Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7e94c7c-c545-4760-88c6-cdc380263798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 134681, number of negative: 1679502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1814183, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074238 -> initscore=-2.523344\n",
      "[LightGBM] [Info] Start training from score -2.523344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9643958333333333\n",
      "Recall: 0.5119073869900772\n",
      "Precision: 0.8689874602283362\n",
      "F1: 0.6442794699229862\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0e5942b-e503-472a-a0ae-4dccb92a7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 143751, number of negative: 1814432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1958183, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.073410 -> initscore=-2.535445\n",
      "[LightGBM] [Info] Start training from score -2.535445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9562297185118104\n",
      "Recall: 0.42535997649133117\n",
      "Precision: 0.8683263347330534\n",
      "F1: 0.5710059171597633\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e27ed6-e6bd-404d-8e1f-8ef3b9d355be",
   "metadata": {},
   "source": [
    "## Croston-like AR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cc3a8-1a9e-4c3e-b2e0-21b549388449",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18b1220a-bc63-4c5c-af32-372c9e2aa8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Processing AS: 11913\n",
      "1 | Processing AS: 131292\n",
      "2 | Processing AS: 133840\n",
      "3 | Processing AS: 134645\n",
      "4 | Processing AS: 135101\n",
      "5 | Processing AS: 136844\n",
      "6 | Processing AS: 136991\n",
      "7 | Processing AS: 138146\n",
      "8 | Processing AS: 138630\n",
      "9 | Processing AS: 138645\n",
      "10 | Processing AS: 139002\n",
      "11 | Processing AS: 139054\n",
      "12 | Processing AS: 139245\n",
      "13 | Processing AS: 141139\n",
      "14 | Processing AS: 142354\n",
      "15 | Processing AS: 147182\n",
      "16 | Processing AS: 149001\n",
      "17 | Processing AS: 149282\n",
      "18 | Processing AS: 151853\n",
      "19 | Processing AS: 152438\n",
      "20 | Processing AS: 18036\n",
      "21 | Processing AS: 18109\n",
      "22 | Processing AS: 19263\n",
      "23 | Processing AS: 197915\n",
      "24 | Processing AS: 198239\n",
      "25 | Processing AS: 200179\n",
      "26 | Processing AS: 200400\n",
      "27 | Processing AS: 200536\n",
      "28 | Processing AS: 200914\n",
      "29 | Processing AS: 201547\n",
      "30 | Processing AS: 2018\n",
      "31 | Processing AS: 202140\n",
      "32 | Processing AS: 202188\n",
      "33 | Processing AS: 202627\n",
      "34 | Processing AS: 204446\n",
      "35 | Processing AS: 20783\n",
      "36 | Processing AS: 208115\n",
      "37 | Processing AS: 208985\n",
      "38 | Processing AS: 20986\n",
      "39 | Processing AS: 210630\n",
      "40 | Processing AS: 212863\n",
      "41 | Processing AS: 212873\n",
      "42 | Processing AS: 212883\n",
      "43 | Processing AS: 215694\n",
      "44 | Processing AS: 23553\n",
      "45 | Processing AS: 24455\n",
      "46 | Processing AS: 24700\n",
      "47 | Processing AS: 24852\n",
      "48 | Processing AS: 25139\n",
      "49 | Processing AS: 25308\n",
      "50 | Processing AS: 25581\n",
      "51 | Processing AS: 263277\n",
      "52 | Processing AS: 263608\n",
      "53 | Processing AS: 263927\n",
      "54 | Processing AS: 266107\n",
      "55 | Processing AS: 266440\n",
      "56 | Processing AS: 266443\n",
      "57 | Processing AS: 267340\n",
      "58 | Processing AS: 268063\n",
      "59 | Processing AS: 26852\n",
      "60 | Processing AS: 268846\n",
      "61 | Processing AS: 269172\n",
      "62 | Processing AS: 270074\n",
      "63 | Processing AS: 270263\n",
      "64 | Processing AS: 27046\n",
      "65 | Processing AS: 271629\n",
      "66 | Processing AS: 29217\n",
      "67 | Processing AS: 30738\n",
      "68 | Processing AS: 31163\n",
      "69 | Processing AS: 328278\n",
      "70 | Processing AS: 328815\n",
      "71 | Processing AS: 328894\n",
      "72 | Processing AS: 33631\n",
      "73 | Processing AS: 34758\n",
      "74 | Processing AS: 36236\n",
      "75 | Processing AS: 39057\n",
      "76 | Processing AS: 393968\n",
      "77 | Processing AS: 394359\n",
      "78 | Processing AS: 39558\n",
      "79 | Processing AS: 395831\n",
      "80 | Processing AS: 399888\n",
      "81 | Processing AS: 400132\n",
      "82 | Processing AS: 41676\n",
      "83 | Processing AS: 42394\n",
      "84 | Processing AS: 42511\n",
      "85 | Processing AS: 43319\n",
      "86 | Processing AS: 44194\n",
      "87 | Processing AS: 44500\n",
      "88 | Processing AS: 46027\n",
      "89 | Processing AS: 49311\n",
      "90 | Processing AS: 49510\n",
      "91 | Processing AS: 5098\n",
      "92 | Processing AS: 53146\n",
      "93 | Processing AS: 56801\n",
      "94 | Processing AS: 57976\n",
      "95 | Processing AS: 58312\n",
      "96 | Processing AS: 58381\n",
      "97 | Processing AS: 60582\n",
      "98 | Processing AS: 8388\n",
      "99 | Processing AS: 9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "X_zero_shots = []\n",
    "y_zero_shots = []\n",
    "\n",
    "for i, (asn, df) in enumerate(as_updates.items()):\n",
    "    print(i, '| Processing AS:', asn)\n",
    "    df = calculate_features(df)\n",
    "    X, y = make_sequences(df, ['updates', 'periods_before_update'], 'updates', 20)\n",
    "    X, y = insert_croston_zero_rows(X, y)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        X_zero_shots.append(X)\n",
    "        y_zero_shots.append((y > 0).astype(int))\n",
    "    \n",
    "    X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "    X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)\n",
    "    X_trains.append(X_train)\n",
    "    y_trains.append(y_train)\n",
    "    X_tests.append(X_test)\n",
    "    y_tests.append(y_test)\n",
    "\n",
    "X_train = np.concatenate(X_trains)\n",
    "y_train = np.concatenate(y_trains)\n",
    "X_test = np.concatenate(X_tests)\n",
    "y_test = np.concatenate(y_tests)\n",
    "X_zero_shot = np.concatenate(X_zero_shots)\n",
    "y_zero_shot = np.concatenate(y_zero_shots)\n",
    "\n",
    "del X_trains\n",
    "del y_trains\n",
    "del X_tests\n",
    "del y_tests\n",
    "del X_zero_shots\n",
    "del y_zero_shots\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82d5d3ea-149f-4922-8897-008a440b2757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1708279, 40), (1708279,), (144000, 40), (144000,), (188800, 40), (188800,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_zero_shot.shape, y_zero_shot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "404b1a08-afe7-4c3b-84d3-4947130e094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, y_train_test = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "836209fd-377a-42b2-93a7-eb1b06b3a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_test = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49da6ea4-6918-4871-90b6-6c141925b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "X_train_test = scaler2.fit_transform(X_train_test)\n",
    "X_zero_shot = scaler2.transform(X_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b23bfdd1-63f8-4606-9e31-db18b718b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = np.concat([np.ones((X_train.shape[0],1)), X_train], axis=1)\n",
    "X_test_reg = np.concat([np.ones((X_test.shape[0],1)), X_test], axis=1)\n",
    "\n",
    "X_train_test_reg = np.concat([np.ones((X_train_test.shape[0],1)), X_train_test], axis=1)\n",
    "X_zero_shot_reg = np.concat([np.ones((X_zero_shot.shape[0],1)), X_zero_shot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2b16e-de5e-4f3d-9f34-abe00ad4ac29",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "afadd46f-01b2-44bb-8a14-be94c270f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9986041666666666\n",
      "Recall: 0.9781355379092788\n",
      "Precision: 1.0\n",
      "F1: 0.9889469342864998\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_reg, y_train)\n",
    "y_pred = model.predict(X_test_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d4a424a-8ec7-4cfb-82e3-52de6f78e8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>5.893082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_1</th>\n",
       "      <td>-0.012762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_1</th>\n",
       "      <td>-0.055316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_2</th>\n",
       "      <td>0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_2</th>\n",
       "      <td>-0.037418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_3</th>\n",
       "      <td>-0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_3</th>\n",
       "      <td>-0.044471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_4</th>\n",
       "      <td>-0.011151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_4</th>\n",
       "      <td>-0.054799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_5</th>\n",
       "      <td>-0.010837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_5</th>\n",
       "      <td>-0.041536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_6</th>\n",
       "      <td>0.008341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_6</th>\n",
       "      <td>-0.053322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_7</th>\n",
       "      <td>0.009105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_7</th>\n",
       "      <td>-0.074583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_8</th>\n",
       "      <td>-0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_8</th>\n",
       "      <td>-0.045540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_9</th>\n",
       "      <td>-0.028411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_9</th>\n",
       "      <td>-0.058313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_10</th>\n",
       "      <td>-0.012475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_10</th>\n",
       "      <td>-0.051511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_11</th>\n",
       "      <td>-0.016924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_11</th>\n",
       "      <td>-0.037914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_12</th>\n",
       "      <td>-0.016492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_12</th>\n",
       "      <td>-0.083433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_13</th>\n",
       "      <td>-0.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_13</th>\n",
       "      <td>-0.040625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_14</th>\n",
       "      <td>-0.024084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_14</th>\n",
       "      <td>-0.054434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_15</th>\n",
       "      <td>-0.037376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_15</th>\n",
       "      <td>-0.075311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_16</th>\n",
       "      <td>-0.042477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_16</th>\n",
       "      <td>-0.118986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_17</th>\n",
       "      <td>-0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_17</th>\n",
       "      <td>-0.133554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_18</th>\n",
       "      <td>-0.038812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_18</th>\n",
       "      <td>-0.171714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_19</th>\n",
       "      <td>-0.009769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_19</th>\n",
       "      <td>-0.133136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_20</th>\n",
       "      <td>214.722573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_20</th>\n",
       "      <td>-0.667293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "bias                 5.893082\n",
       "updates_1           -0.012762\n",
       "periods_before_1    -0.055316\n",
       "updates_2            0.008543\n",
       "periods_before_2    -0.037418\n",
       "updates_3           -0.006100\n",
       "periods_before_3    -0.044471\n",
       "updates_4           -0.011151\n",
       "periods_before_4    -0.054799\n",
       "updates_5           -0.010837\n",
       "periods_before_5    -0.041536\n",
       "updates_6            0.008341\n",
       "periods_before_6    -0.053322\n",
       "updates_7            0.009105\n",
       "periods_before_7    -0.074583\n",
       "updates_8           -0.008047\n",
       "periods_before_8    -0.045540\n",
       "updates_9           -0.028411\n",
       "periods_before_9    -0.058313\n",
       "updates_10          -0.012475\n",
       "periods_before_10   -0.051511\n",
       "updates_11          -0.016924\n",
       "periods_before_11   -0.037914\n",
       "updates_12          -0.016492\n",
       "periods_before_12   -0.083433\n",
       "updates_13          -0.020291\n",
       "periods_before_13   -0.040625\n",
       "updates_14          -0.024084\n",
       "periods_before_14   -0.054434\n",
       "updates_15          -0.037376\n",
       "periods_before_15   -0.075311\n",
       "updates_16          -0.042477\n",
       "periods_before_16   -0.118986\n",
       "updates_17          -0.037267\n",
       "periods_before_17   -0.133554\n",
       "updates_18          -0.038812\n",
       "periods_before_18   -0.171714\n",
       "updates_19          -0.009769\n",
       "periods_before_19   -0.133136\n",
       "updates_20         214.722573\n",
       "periods_before_20   -0.667293"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['bias']\n",
    "for i in range(1, 21):\n",
    "    feature_names.extend([f'updates_{i}', f'periods_before_{i}'])\n",
    "    \n",
    "pd.DataFrame(model.coef_, columns=feature_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df42de8a-e817-4840-a15f-77ae1c704a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995074152542373\n",
      "Recall: 0.993081386698408\n",
      "Precision: 1.0\n",
      "F1: 0.9965286850061588\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_test_reg, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot_reg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6571d8-357a-4d44-924b-8b079aed35bc",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e052ad76-3952-4a83-9b74-31462768f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c363495-488a-4855-b746-38fe2589cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557ecdd-c50f-4dcd-bc95-ba6557ec09c5",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b08d981-726f-4f58-be2e-86d9c84c0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 132903, number of negative: 1575376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.279978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10082\n",
      "[LightGBM] [Info] Number of data points in the train set: 1708279, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077799 -> initscore=-2.472630\n",
      "[LightGBM] [Info] Start training from score -2.472630\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary', n_estimators=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33db668f-6bdd-4ac8-8341-2a26ba19dde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 142096, number of negative: 1710183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.057038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10087\n",
      "[LightGBM] [Info] Number of data points in the train set: 1852279, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076714 -> initscore=-2.487853\n",
      "[LightGBM] [Info] Start training from score -2.487853\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary', n_estimators=5)\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cecbaa-dcd7-40fa-a080-fc09d4601da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
