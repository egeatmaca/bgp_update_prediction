{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1fd9f6c-6358-41f9-88e6-2fd357ac4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6e136-10a0-48c0-8ee2-057b9e50dc32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6a42a94-d50d-4c44-865c-776e077bdf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 100/100 [01:07<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "AS_UPDATES_ROOT_DIR = './data/asn_updates'\n",
    "\n",
    "as_updates = {}\n",
    "as_updates_dirs = sorted(glob(AS_UPDATES_ROOT_DIR+'/*'))\n",
    "for dir_path in tqdm(as_updates_dirs):\n",
    "    asn = dir_path.split('/')[-1]\n",
    "    as_updates_files = sorted(glob(dir_path+'/*'))\n",
    "    as_df_list = [pd.read_csv(file_path) for file_path in as_updates_files]\n",
    "    as_df =  pd.concat(as_df_list).reset_index(drop=True)\n",
    "    del as_df_list\n",
    "    gc.collect()\n",
    "    as_df = as_df.sort_values('time')\n",
    "    as_updates[asn] = as_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d08ed-4ada-4183-9990-b24aa370fba2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3098ed7e-3529-43ae-ba67-e278f0ca68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "    df['minute'] = df.time // 60\n",
    "    df = df.groupby('minute')[['prefix']]\\\n",
    "                       .count()\\\n",
    "                       .rename(columns={'prefix': 'updates'})\n",
    "    minutes = pd.Series(df.index, index=df.index)\n",
    "    df['periods_before_update'] = minutes - minutes.shift(1)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eca86c47-31be-4e94-a651-444f66946cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_index(df):\n",
    "    index_interpolated = np.arange(int(df.index.min()), int(df.index.max()))\n",
    "    df = df.reindex(index_interpolated).fillna({'updates': 0})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b366c28-d27b-4cce-a9e3-489207c60955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(df, feature_cols, target_col, lag):    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(df.shape[0]-lag):\n",
    "        X.append(df.iloc[i:i+lag][feature_cols].to_numpy().reshape(-1))\n",
    "        y.append(df.iloc[i+lag][target_col])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14decbb0-60c2-48a8-a831-f0d5e4230ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_croston_zero_rows(X, y):\n",
    "    zero_rows = {}\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        row_ = X[i].copy()\n",
    "        n_zero_rows = int(row_[-1] - 1)\n",
    "\n",
    "        if n_zero_rows > 0:\n",
    "            row_[-2] = 0\n",
    "            row_[-1] = 1\n",
    "            zero_rows[i] = [row_]\n",
    "        \n",
    "        for _ in range(n_zero_rows-1):\n",
    "            row_ = row_.copy()\n",
    "            row_[-1] += 1\n",
    "            zero_rows[i].append(row_)\n",
    "    \n",
    "    for i in sorted(zero_rows.keys())[-1::-1]:\n",
    "        X_zeros = np.array(zero_rows[i])\n",
    "        y_zeros = np.zeros(X_zeros.shape[0])\n",
    "        \n",
    "        X_before = X[:i]\n",
    "        y_before = y[:i]\n",
    "        \n",
    "        X_after = X[i:]\n",
    "        y_after = y[i:]\n",
    "    \n",
    "        X = np.concatenate([X_before, X_zeros, X_after])\n",
    "        y = np.concatenate([y_before, y_zeros, y_after])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34525908-84bf-4336-b9e8-71526444e9be",
   "metadata": {},
   "source": [
    "# Single AS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c15fd5c0-1cd6-42fd-8d6a-22924bd7fb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 24 * 60\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788a3ce-0661-484a-a362-44cbd779d809",
   "metadata": {},
   "source": [
    "## AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "047c9721-7c0f-44c9-af45-1239f31a0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_features(as_updates['25139'])\n",
    "df_ar = interpolate_index(df)\n",
    "X, y = make_sequences(df_ar, ['updates'], 'updates', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64f0932d-1c69-43bc-8d62-dd980d9f71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e527edc3-9ca1-464f-b0ba-a1ea16d161f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18609, 20), (18609,), (1440, 20), (1440,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d709d9a-a231-47ae-a7fd-d2824bc9a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ad6ba45-c782-41e4-9bf7-1e46554cb70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9680555555555556\n",
      "Recall: 0.7704918032786885\n",
      "Precision: 0.9724137931034482\n",
      "F1: 0.8597560975609756\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ccfdfdbf-ccc8-4d47-9e62-46b245e63913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784722222222222\n",
      "Recall: 0.8961748633879781\n",
      "Precision: 0.9318181818181818\n",
      "F1: 0.9136490250696379\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16beac2c-a1cc-449d-b912-ee79cea64817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2687, number of negative: 15922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 18609, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144392 -> initscore=-1.779276\n",
      "[LightGBM] [Info] Start training from score -1.779276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98125\n",
      "Recall: 0.8852459016393442\n",
      "Precision: 0.9642857142857143\n",
      "F1: 0.9230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6314f42-f774-41d5-ac75-d05c2e3a40a6",
   "metadata": {},
   "source": [
    "## Croston-like AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f8bd6e4-e08b-4daf-88ac-2996d2c8a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_features(as_updates['25139'])\n",
    "X, y = make_sequences(df, ['updates', 'periods_before_update'], 'updates', 20)\n",
    "X, y = insert_croston_zero_rows(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "969b3c8c-a77b-4a5f-a9ce-c8a7e753ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b393e020-96c8-4de9-a9a9-ee9704c661de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18447, 40), (18447,), (1440, 40), (1440,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6492bb50-bcf6-4adf-8430-ef49fba559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "501433ee-c6a6-4771-9b65-2e9c55d6d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9923611111111111\n",
      "Recall: 0.9402173913043478\n",
      "Precision: 1.0\n",
      "F1: 0.969187675070028\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2e6fe5a-bd55-4c37-80ef-eaf667c442f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "531ed736-8533-461c-ae13-c38dea9b15ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2670, number of negative: 15777\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 18447, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144739 -> initscore=-1.776475\n",
      "[LightGBM] [Info] Start training from score -1.776475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42125f4d-238c-4a65-a0dc-06a17c24ebc6",
   "metadata": {},
   "source": [
    "# Multiple AS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853ded9-7dd5-4ee8-b136-0172f2f42e33",
   "metadata": {},
   "source": [
    "## AR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314c227-13e6-4eb7-9b1c-ddeee940fd6b",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89fd5328-6923-4620-a67f-5263e53730d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Processing AS: 11913\n",
      "1 | Processing AS: 131292\n",
      "2 | Processing AS: 133840\n",
      "3 | Processing AS: 134645\n",
      "4 | Processing AS: 135101\n",
      "5 | Processing AS: 136844\n",
      "6 | Processing AS: 136991\n",
      "7 | Processing AS: 138146\n",
      "8 | Processing AS: 138630\n",
      "9 | Processing AS: 138645\n",
      "10 | Processing AS: 139002\n",
      "11 | Processing AS: 139054\n",
      "12 | Processing AS: 139245\n",
      "13 | Processing AS: 141139\n",
      "14 | Processing AS: 142354\n",
      "15 | Processing AS: 147182\n",
      "16 | Processing AS: 149001\n",
      "17 | Processing AS: 149282\n",
      "18 | Processing AS: 151853\n",
      "19 | Processing AS: 152438\n",
      "20 | Processing AS: 18036\n",
      "21 | Processing AS: 18109\n",
      "22 | Processing AS: 19263\n",
      "23 | Processing AS: 197915\n",
      "24 | Processing AS: 198239\n",
      "25 | Processing AS: 200179\n",
      "26 | Processing AS: 200400\n",
      "27 | Processing AS: 200536\n",
      "28 | Processing AS: 200914\n",
      "29 | Processing AS: 201547\n",
      "30 | Processing AS: 2018\n",
      "31 | Processing AS: 202140\n",
      "32 | Processing AS: 202188\n",
      "33 | Processing AS: 202627\n",
      "34 | Processing AS: 204446\n",
      "35 | Processing AS: 20783\n",
      "36 | Processing AS: 208115\n",
      "37 | Processing AS: 208985\n",
      "38 | Processing AS: 20986\n",
      "39 | Processing AS: 210630\n",
      "40 | Processing AS: 212863\n",
      "41 | Processing AS: 212873\n",
      "42 | Processing AS: 212883\n",
      "43 | Processing AS: 215694\n",
      "44 | Processing AS: 23553\n",
      "45 | Processing AS: 24455\n",
      "46 | Processing AS: 24700\n",
      "47 | Processing AS: 24852\n",
      "48 | Processing AS: 25139\n",
      "49 | Processing AS: 25308\n",
      "50 | Processing AS: 25581\n",
      "51 | Processing AS: 263277\n",
      "52 | Processing AS: 263608\n",
      "53 | Processing AS: 263927\n",
      "54 | Processing AS: 266107\n",
      "55 | Processing AS: 266440\n",
      "56 | Processing AS: 266443\n",
      "57 | Processing AS: 267340\n",
      "58 | Processing AS: 268063\n",
      "59 | Processing AS: 26852\n",
      "60 | Processing AS: 268846\n",
      "61 | Processing AS: 269172\n",
      "62 | Processing AS: 270074\n",
      "63 | Processing AS: 270263\n",
      "64 | Processing AS: 27046\n",
      "65 | Processing AS: 271629\n",
      "66 | Processing AS: 29217\n",
      "67 | Processing AS: 30738\n",
      "68 | Processing AS: 31163\n",
      "69 | Processing AS: 328278\n",
      "70 | Processing AS: 328815\n",
      "71 | Processing AS: 328894\n",
      "72 | Processing AS: 33631\n",
      "73 | Processing AS: 34758\n",
      "74 | Processing AS: 36236\n",
      "75 | Processing AS: 39057\n",
      "76 | Processing AS: 393968\n",
      "77 | Processing AS: 394359\n",
      "78 | Processing AS: 39558\n",
      "79 | Processing AS: 395831\n",
      "80 | Processing AS: 399888\n",
      "81 | Processing AS: 400132\n",
      "82 | Processing AS: 41676\n",
      "83 | Processing AS: 42394\n",
      "84 | Processing AS: 42511\n",
      "85 | Processing AS: 43319\n",
      "86 | Processing AS: 44194\n",
      "87 | Processing AS: 44500\n",
      "88 | Processing AS: 46027\n",
      "89 | Processing AS: 49311\n",
      "90 | Processing AS: 49510\n",
      "91 | Processing AS: 5098\n",
      "92 | Processing AS: 53146\n",
      "93 | Processing AS: 56801\n",
      "94 | Processing AS: 57976\n",
      "95 | Processing AS: 58312\n",
      "96 | Processing AS: 58381\n",
      "97 | Processing AS: 60582\n",
      "98 | Processing AS: 8388\n",
      "99 | Processing AS: 9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "X_zero_shots = []\n",
    "y_zero_shots = []\n",
    "\n",
    "for i, (asn, df) in enumerate(as_updates.items()):\n",
    "    print(i, '| Processing AS:', asn)\n",
    "    df = calculate_features(df)\n",
    "    df = interpolate_index(df)\n",
    "    X, y = make_sequences(df, ['updates'], 'updates', 20)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        X_zero_shots.append(X)\n",
    "        y_zero_shots.append((y > 0).astype(int))\n",
    "    \n",
    "    X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "    X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)\n",
    "    X_trains.append(X_train)\n",
    "    y_trains.append(y_train)\n",
    "    X_tests.append(X_test)\n",
    "    y_tests.append(y_test)\n",
    "\n",
    "X_train = np.concatenate(X_trains)\n",
    "y_train = np.concatenate(y_trains)\n",
    "X_test = np.concatenate(X_tests)\n",
    "y_test = np.concatenate(y_tests)\n",
    "X_zero_shot = np.concatenate(X_zero_shots)\n",
    "y_zero_shot = np.concatenate(y_zero_shots)\n",
    "\n",
    "del X_trains\n",
    "del y_trains\n",
    "del X_tests\n",
    "del y_tests\n",
    "del X_zero_shots\n",
    "del y_zero_shots\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4d87613a-8402-45aa-beae-55cc1db83efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1814183, 20), (1814183,), (144000, 20), (144000,), (198765, 20), (198765,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_zero_shot.shape, y_zero_shot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf4da46b-0d0b-4742-b409-8f5d0c06f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_test = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb106047-0b13-477d-a54d-b7bd53d58c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, y_train_test = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a309039b-5188-48d5-87ea-dbd41a512fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "X_train_test = scaler2.fit_transform(X_train_test)\n",
    "X_zero_shot = scaler2.transform(X_zero_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6f789-cd39-47c6-a563-dc12af3a3e36",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27c7cbcc-6d85-496d-bc42-528ef8491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500347222222222\n",
      "Recall: 0.23836824696802647\n",
      "Precision: 0.8828093099224174\n",
      "F1: 0.3753798072749371\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "43c0506f-ead2-4bf4-b748-70524b1c77e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>updates_1</th>\n",
       "      <td>0.274407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_2</th>\n",
       "      <td>0.036595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_3</th>\n",
       "      <td>0.050525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_4</th>\n",
       "      <td>0.067109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_5</th>\n",
       "      <td>0.129664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_6</th>\n",
       "      <td>0.161972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_7</th>\n",
       "      <td>0.039610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_8</th>\n",
       "      <td>0.104192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_9</th>\n",
       "      <td>0.094269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_10</th>\n",
       "      <td>0.033865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_11</th>\n",
       "      <td>0.253724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_12</th>\n",
       "      <td>0.059350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_13</th>\n",
       "      <td>0.103459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_14</th>\n",
       "      <td>0.084867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_15</th>\n",
       "      <td>0.105316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_16</th>\n",
       "      <td>0.119094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_17</th>\n",
       "      <td>0.122856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_18</th>\n",
       "      <td>0.183450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_19</th>\n",
       "      <td>0.235446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_20</th>\n",
       "      <td>4.535096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "updates_1   0.274407\n",
       "updates_2   0.036595\n",
       "updates_3   0.050525\n",
       "updates_4   0.067109\n",
       "updates_5   0.129664\n",
       "updates_6   0.161972\n",
       "updates_7   0.039610\n",
       "updates_8   0.104192\n",
       "updates_9   0.094269\n",
       "updates_10  0.033865\n",
       "updates_11  0.253724\n",
       "updates_12  0.059350\n",
       "updates_13  0.103459\n",
       "updates_14  0.084867\n",
       "updates_15  0.105316\n",
       "updates_16  0.119094\n",
       "updates_17  0.122856\n",
       "updates_18  0.183450\n",
       "updates_19  0.235446\n",
       "updates_20  4.535096"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = []\n",
    "for i in range(1, 21):\n",
    "    feature_names.extend([f'updates_{i}'])\n",
    "    \n",
    "pd.DataFrame(model.coef_, columns=feature_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38bece44-c88f-4227-8e4b-cda742ff481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8517545845596559\n",
      "Recall: 0.4126506024096386\n",
      "Precision: 0.20736119314825754\n",
      "F1: 0.276019656019656\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910b122-03d4-463a-81dd-bdd381662138",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c30badb5-3938-41d3-b73f-9642b95843a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9573541666666666\n",
      "Recall: 0.5317530319735392\n",
      "Precision: 0.7180288819413428\n",
      "F1: 0.6110090580857668\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f47366c2-b281-47e1-9d8b-45db385bb5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07122481322164365\n",
      "Recall: 0.992873934763444\n",
      "Precision: 0.06824861381838748\n",
      "F1: 0.12771808465398463\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd13c17-9046-4b56-8bda-28707f696620",
   "metadata": {},
   "source": [
    "### Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7e94c7c-c545-4760-88c6-cdc380263798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 134681, number of negative: 1679502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1814183, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074238 -> initscore=-2.523344\n",
      "[LightGBM] [Info] Start training from score -2.523344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9643958333333333\n",
      "Recall: 0.5119073869900772\n",
      "Precision: 0.8689874602283362\n",
      "F1: 0.6442794699229862\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0e5942b-e503-472a-a0ae-4dccb92a7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 143751, number of negative: 1814432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1958183, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.073410 -> initscore=-2.535445\n",
      "[LightGBM] [Info] Start training from score -2.535445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06853319246346187\n",
      "Recall: 0.9999265354099324\n",
      "Precision: 0.06848198517758222\n",
      "F1: 0.12818496456572412\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary')\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e27ed6-e6bd-404d-8e1f-8ef3b9d355be",
   "metadata": {},
   "source": [
    "## Croston-like AR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cc3a8-1a9e-4c3e-b2e0-21b549388449",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18b1220a-bc63-4c5c-af32-372c9e2aa8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Processing AS: 11913\n",
      "1 | Processing AS: 131292\n",
      "2 | Processing AS: 133840\n",
      "3 | Processing AS: 134645\n",
      "4 | Processing AS: 135101\n",
      "5 | Processing AS: 136844\n",
      "6 | Processing AS: 136991\n",
      "7 | Processing AS: 138146\n",
      "8 | Processing AS: 138630\n",
      "9 | Processing AS: 138645\n",
      "10 | Processing AS: 139002\n",
      "11 | Processing AS: 139054\n",
      "12 | Processing AS: 139245\n",
      "13 | Processing AS: 141139\n",
      "14 | Processing AS: 142354\n",
      "15 | Processing AS: 147182\n",
      "16 | Processing AS: 149001\n",
      "17 | Processing AS: 149282\n",
      "18 | Processing AS: 151853\n",
      "19 | Processing AS: 152438\n",
      "20 | Processing AS: 18036\n",
      "21 | Processing AS: 18109\n",
      "22 | Processing AS: 19263\n",
      "23 | Processing AS: 197915\n",
      "24 | Processing AS: 198239\n",
      "25 | Processing AS: 200179\n",
      "26 | Processing AS: 200400\n",
      "27 | Processing AS: 200536\n",
      "28 | Processing AS: 200914\n",
      "29 | Processing AS: 201547\n",
      "30 | Processing AS: 2018\n",
      "31 | Processing AS: 202140\n",
      "32 | Processing AS: 202188\n",
      "33 | Processing AS: 202627\n",
      "34 | Processing AS: 204446\n",
      "35 | Processing AS: 20783\n",
      "36 | Processing AS: 208115\n",
      "37 | Processing AS: 208985\n",
      "38 | Processing AS: 20986\n",
      "39 | Processing AS: 210630\n",
      "40 | Processing AS: 212863\n",
      "41 | Processing AS: 212873\n",
      "42 | Processing AS: 212883\n",
      "43 | Processing AS: 215694\n",
      "44 | Processing AS: 23553\n",
      "45 | Processing AS: 24455\n",
      "46 | Processing AS: 24700\n",
      "47 | Processing AS: 24852\n",
      "48 | Processing AS: 25139\n",
      "49 | Processing AS: 25308\n",
      "50 | Processing AS: 25581\n",
      "51 | Processing AS: 263277\n",
      "52 | Processing AS: 263608\n",
      "53 | Processing AS: 263927\n",
      "54 | Processing AS: 266107\n",
      "55 | Processing AS: 266440\n",
      "56 | Processing AS: 266443\n",
      "57 | Processing AS: 267340\n",
      "58 | Processing AS: 268063\n",
      "59 | Processing AS: 26852\n",
      "60 | Processing AS: 268846\n",
      "61 | Processing AS: 269172\n",
      "62 | Processing AS: 270074\n",
      "63 | Processing AS: 270263\n",
      "64 | Processing AS: 27046\n",
      "65 | Processing AS: 271629\n",
      "66 | Processing AS: 29217\n",
      "67 | Processing AS: 30738\n",
      "68 | Processing AS: 31163\n",
      "69 | Processing AS: 328278\n",
      "70 | Processing AS: 328815\n",
      "71 | Processing AS: 328894\n",
      "72 | Processing AS: 33631\n",
      "73 | Processing AS: 34758\n",
      "74 | Processing AS: 36236\n",
      "75 | Processing AS: 39057\n",
      "76 | Processing AS: 393968\n",
      "77 | Processing AS: 394359\n",
      "78 | Processing AS: 39558\n",
      "79 | Processing AS: 395831\n",
      "80 | Processing AS: 399888\n",
      "81 | Processing AS: 400132\n",
      "82 | Processing AS: 41676\n",
      "83 | Processing AS: 42394\n",
      "84 | Processing AS: 42511\n",
      "85 | Processing AS: 43319\n",
      "86 | Processing AS: 44194\n",
      "87 | Processing AS: 44500\n",
      "88 | Processing AS: 46027\n",
      "89 | Processing AS: 49311\n",
      "90 | Processing AS: 49510\n",
      "91 | Processing AS: 5098\n",
      "92 | Processing AS: 53146\n",
      "93 | Processing AS: 56801\n",
      "94 | Processing AS: 57976\n",
      "95 | Processing AS: 58312\n",
      "96 | Processing AS: 58381\n",
      "97 | Processing AS: 60582\n",
      "98 | Processing AS: 8388\n",
      "99 | Processing AS: 9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "X_zero_shots = []\n",
    "y_zero_shots = []\n",
    "\n",
    "for i, (asn, df) in enumerate(as_updates.items()):\n",
    "    print(i, '| Processing AS:', asn)\n",
    "    df = calculate_features(df)\n",
    "    X, y = make_sequences(df, ['updates', 'periods_before_update'], 'updates', 20)\n",
    "    X, y = insert_croston_zero_rows(X, y)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        X_zero_shots.append(X)\n",
    "        y_zero_shots.append((y > 0).astype(int))\n",
    "    \n",
    "    X_train, y_train = X[:-test_size], (y[:-test_size] > 0).astype(int)\n",
    "    X_test, y_test = X[-test_size:], (y[-test_size:] > 0).astype(int)\n",
    "    X_trains.append(X_train)\n",
    "    y_trains.append(y_train)\n",
    "    X_tests.append(X_test)\n",
    "    y_tests.append(y_test)\n",
    "\n",
    "X_train = np.concatenate(X_trains)\n",
    "y_train = np.concatenate(y_trains)\n",
    "X_test = np.concatenate(X_tests)\n",
    "y_test = np.concatenate(y_tests)\n",
    "X_zero_shot = np.concatenate(X_zero_shots)\n",
    "y_zero_shot = np.concatenate(y_zero_shots)\n",
    "\n",
    "del X_trains\n",
    "del y_trains\n",
    "del X_tests\n",
    "del y_tests\n",
    "del X_zero_shots\n",
    "del y_zero_shots\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82d5d3ea-149f-4922-8897-008a440b2757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1708279, 40), (1708279,), (144000, 40), (144000,), (188800, 40), (188800,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_zero_shot.shape, y_zero_shot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "836209fd-377a-42b2-93a7-eb1b06b3a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_test = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "404b1a08-afe7-4c3b-84d3-4947130e094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, y_train_test = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49da6ea4-6918-4871-90b6-6c141925b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "X_train_test = scaler2.fit_transform(X_train_test)\n",
    "X_zero_shot = scaler2.transform(X_zero_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2b16e-de5e-4f3d-9f34-abe00ad4ac29",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "afadd46f-01b2-44bb-8a14-be94c270f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988402777777777\n",
      "Recall: 0.9818340041335799\n",
      "Precision: 1.0\n",
      "F1: 0.9908337449914923\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d4a424a-8ec7-4cfb-82e3-52de6f78e8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>updates_1</th>\n",
       "      <td>-0.024737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_1</th>\n",
       "      <td>-0.054723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_2</th>\n",
       "      <td>0.006528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_2</th>\n",
       "      <td>-0.035427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_3</th>\n",
       "      <td>-0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_3</th>\n",
       "      <td>-0.026815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_4</th>\n",
       "      <td>-0.009391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_4</th>\n",
       "      <td>-0.042382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_5</th>\n",
       "      <td>-0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_5</th>\n",
       "      <td>-0.026195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_6</th>\n",
       "      <td>-0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_6</th>\n",
       "      <td>-0.050852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_7</th>\n",
       "      <td>-0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_7</th>\n",
       "      <td>-0.076427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_8</th>\n",
       "      <td>-0.007475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_8</th>\n",
       "      <td>-0.039590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_9</th>\n",
       "      <td>-0.013689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_9</th>\n",
       "      <td>-0.042174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_10</th>\n",
       "      <td>-0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_10</th>\n",
       "      <td>-0.061598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_11</th>\n",
       "      <td>-0.011313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_11</th>\n",
       "      <td>-0.029638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_12</th>\n",
       "      <td>-0.010154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_12</th>\n",
       "      <td>-0.067483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_13</th>\n",
       "      <td>-0.042680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_13</th>\n",
       "      <td>-0.043399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_14</th>\n",
       "      <td>-0.012264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_14</th>\n",
       "      <td>-0.036299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_15</th>\n",
       "      <td>-0.046863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_15</th>\n",
       "      <td>-0.078290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_16</th>\n",
       "      <td>-0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_16</th>\n",
       "      <td>-0.113605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_17</th>\n",
       "      <td>-0.115909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_17</th>\n",
       "      <td>-0.112045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_18</th>\n",
       "      <td>-0.021842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_18</th>\n",
       "      <td>-0.177616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_19</th>\n",
       "      <td>-0.010918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_19</th>\n",
       "      <td>-0.154456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updates_20</th>\n",
       "      <td>220.426080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periods_before_20</th>\n",
       "      <td>-0.756306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "updates_1           -0.024737\n",
       "periods_before_1    -0.054723\n",
       "updates_2            0.006528\n",
       "periods_before_2    -0.035427\n",
       "updates_3           -0.006182\n",
       "periods_before_3    -0.026815\n",
       "updates_4           -0.009391\n",
       "periods_before_4    -0.042382\n",
       "updates_5           -0.001742\n",
       "periods_before_5    -0.026195\n",
       "updates_6           -0.002228\n",
       "periods_before_6    -0.050852\n",
       "updates_7           -0.007816\n",
       "periods_before_7    -0.076427\n",
       "updates_8           -0.007475\n",
       "periods_before_8    -0.039590\n",
       "updates_9           -0.013689\n",
       "periods_before_9    -0.042174\n",
       "updates_10          -0.006099\n",
       "periods_before_10   -0.061598\n",
       "updates_11          -0.011313\n",
       "periods_before_11   -0.029638\n",
       "updates_12          -0.010154\n",
       "periods_before_12   -0.067483\n",
       "updates_13          -0.042680\n",
       "periods_before_13   -0.043399\n",
       "updates_14          -0.012264\n",
       "periods_before_14   -0.036299\n",
       "updates_15          -0.046863\n",
       "periods_before_15   -0.078290\n",
       "updates_16          -0.008741\n",
       "periods_before_16   -0.113605\n",
       "updates_17          -0.115909\n",
       "periods_before_17   -0.112045\n",
       "updates_18          -0.021842\n",
       "periods_before_18   -0.177616\n",
       "updates_19          -0.010918\n",
       "periods_before_19   -0.154456\n",
       "updates_20         220.426080\n",
       "periods_before_20   -0.756306"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = []\n",
    "for i in range(1, 21):\n",
    "    feature_names.extend([f'updates_{i}', f'periods_before_{i}'])\n",
    "    \n",
    "pd.DataFrame(model.coef_, columns=feature_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df42de8a-e817-4840-a15f-77ae1c704a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175794491525424\n",
      "Recall: 0.9947180479095372\n",
      "Precision: 0.4632895603062957\n",
      "F1: 0.6321537479611375\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6571d8-357a-4d44-924b-8b079aed35bc",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e052ad76-3952-4a83-9b74-31462768f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c363495-488a-4855-b746-38fe2589cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07119703389830509\n",
      "Recall: 1.0\n",
      "Precision: 0.07119703389830509\n",
      "F1: 0.13292985631075643\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557ecdd-c50f-4dcd-bc95-ba6557ec09c5",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b08d981-726f-4f58-be2e-86d9c84c0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 132903, number of negative: 1575376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.187011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10082\n",
      "[LightGBM] [Info] Number of data points in the train set: 1708279, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077799 -> initscore=-2.472630\n",
      "[LightGBM] [Info] Start training from score -2.472630\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary', n_estimators=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33db668f-6bdd-4ac8-8341-2a26ba19dde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 142096, number of negative: 1710183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10087\n",
      "[LightGBM] [Info] Number of data points in the train set: 1852279, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076714 -> initscore=-2.487853\n",
      "[LightGBM] [Info] Start training from score -2.487853\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.07119703389830509\n",
      "Recall: 1.0\n",
      "Precision: 0.07119703389830509\n",
      "F1: 0.13292985631075643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Git/pybgpstream-test/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective='binary', n_estimators=5)\n",
    "model.fit(X_train_test, y_train_test)\n",
    "y_pred = model.predict(X_zero_shot)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_zero_shot, y_pred))\n",
    "print('Recall:', recall_score(y_zero_shot, y_pred))\n",
    "print('Precision:', precision_score(y_zero_shot, y_pred))\n",
    "print('F1:', f1_score(y_zero_shot, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cecbaa-dcd7-40fa-a080-fc09d4601da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
